# Common
import numpy as np
import sys
from matplotlib import pyplot as plt
import scipy as sp

# Specialized

from colossus.lss import mass_function
from colossus.cosmology import cosmology

# Local
from Utillity import *


def generate_semi_analytic_halo_catalogue(volume, mass_params, z, h, visual_debugging=False, path="./"):
    """ Function to generate the semi analytic halo catalogue (without coordinates) for galaxy testing

    :param volume: float, cosmological volume within which to generate the catalog.
    :param mass_params: tuple, (mass low, mass high, spacing) in log10.
    :param z: float, redshift.
    :param h: float, reduced hubble constant.
    :param visual_debugging: bool, if to generate figures for debugging.
    :param path: path to directory where figures should be written.
    :return:
    """
    if visual_debugging:
        print("You have activated visual debugging for generate_semi_analytic_halo_catalogue().")
        ValidatePath(path)
        erase_all_in_folder(path)

    bin_width = mass_params[2]
    mass_range = 10 ** np.arange(mass_params[0], mass_params[1], mass_params[2]) + np.log10(h)  # h^-1
    local_mass_function = mass_function.massFunction(mass_range, z, mdef='200m', model='tinker08', q_out='dndlnM') \
        * np.log(10) / h  # dn/dlog10M

    # Plot the halo mass function generated by colossus.
    if visual_debugging:
        fig = plt.figure()
        plt.xlabel('M200m')
        plt.ylabel('M')
        plt.title('Halo Mass function from Colossus')
        plt.loglog()
        plt.plot(mass_range, local_mass_function, '-', label='z = %.1f' % z)
        plt.legend()
        save_path = path + 'Colossus_HMF.png'
        print("Writing file: {}".format(save_path))
        fig.savefig(save_path)
        plt.close()

    # We determine the Cumulative HMF starting from the high mass end, multiplied by the bin width.
    # This effectively gives the cumulative probability of a halo existing.
    cumulative_mass_function = np.flip(np.cumsum(np.flip(local_mass_function, 0)), 0) * bin_width

    ########################################################################
    # Interpolation Tests
    # Interpolator for the testing - we will update this with the volume in a second.
    # This is essentially for a volume of size unity.
    interpolator = sp.interpolate.interp1d(cumulative_mass_function, mass_range)

    sample_index = int(np.floor(len(cumulative_mass_function) / 2))  # index of the half way point
    num_test = cumulative_mass_function[sample_index]  # The value of the cum function at this index
    mass_test = interpolator(num_test)  # Interpolate to get the mass that this predicts
    # Check that these values are equivalent.
    assert mass_range[sample_index] == mass_test, \
        "Interpolation method incorrect: Back interpolation at midpoint failed"
    # Check first element is equivalent to the total to 10 SF accuracy
    assert np.round(cumulative_mass_function[0], 10) ==\
        np.round(np.sum(local_mass_function) * bin_width, 10), "Final cum sum element != total sum"
    ########################################################################

    # Multiply by volume
    cumulative_mass_function = cumulative_mass_function * volume

    # Get the maximum cumulative number.
    max_number = np.floor(cumulative_mass_function[0])
    range_numbers = np.arange(max_number)

    # Update interpolator
    interpolator = sp.interpolate.interp1d(cumulative_mass_function, mass_range)
    mass_catalog = interpolator(range_numbers[range_numbers >= np.amin(cumulative_mass_function)])

    # Reconstruct HMF
    width = 0.1
    bins = np.arange(10, 16, width)
    hist = np.histogram(np.log10(mass_catalog), bins=bins)[0]
    hmf = (hist/volume)/width

    # Plot both as a comparison
    if visual_debugging:
        # Plot both as a comparison
        plt.figure()
        plt.loglog()

        bins_power = 10 ** (bins[0:-1])

        plt.plot(bins_power[hmf != 0], hmf[hmf != 0], 'o', label='Reconstructed')
        plt.plot(mass_range, local_mass_function, label='Original')

        plt.legend()
        plt.xlabel("Halo Mass")
        plt.ylabel("Number Density")
        plt.title("Reconstructed HMF")

        save_path = path + 'HMF_Validation.png'
        print("Writing file: {}".format(save_path))
        plt.savefig(save_path)
        plt.close()

    mass_catalog = np.log10(mass_catalog)
    return mass_catalog


def halo_mass_to_stellar_mass(halo_mass, z, formula="Grylls18", scatter=0.001,
                              visual_debugging=False, debugging_volume=500 ** 3, path="./"):
    """Function to generate stellar masses from halo masses.

    This is based on Grylls 2018, but also has the option to use the
    parameters from Moster. This is a simplified version of Pip's
    DarkMatterToStellarMass() function.

    :param halo_mass: array, of halo masses (log10)
    :param z: float, the value of redshift
    :param formula: string, the method to use. Options currently include "Grylls18" and "Moster"
    :param scatter: bool, to scatter or not
    :param scatter_scale: float, the magnitude of the scatter
    :param visual_debugging: bool, flag to active visual debugging mode, which generates graphs
    :param debugging_volume float, cosmological volume for visual debugging mode
    :param path: string, path for the files for visual debugging mode.
    :return:
    """
    if visual_debugging:
        print("You have activated visual debugging for halo_mass_to_stellar_mass()")
        ValidatePath(path)
        erase_all_in_folder(path)

    # If conditions to set the correct parameters.
    if formula == "Grylls18":
        z_parameter = np.divide(z - 0.1, z + 1)
        m_10, shm_norm_10, beta10, gamma10, scatter = 11.95, 0.032, 1.61, 0.54, 0.11
        m_11, shm_norm_11, beta11, gamma11 = 0.4, -0.02, -0.6, -0.1
    elif formula == "Moster":
        z_parameter = np.divide(z, z + 1)
        m_10, shm_norm_10, beta10, gamma10 = 11.590, 0.0351, 1.376, 0.608
        m_11, shm_norm_11, beta11, gamma11 = 1.195, -0.0247, -0.826, 0.329
    else:
        assert False, "Unrecognised formula"

    # Create full parameters
    m = m_10 + m_11 * z_parameter
    n = shm_norm_10 + shm_norm_11 * z_parameter
    b = beta10 + beta11 * z_parameter
    g = gamma10 + gamma11 * z_parameter
    # Full formula
    # DM = self.effective_halo_mass
    internal_stellar_mass = np.log10(np.power(10, halo_mass) *
                                     (2 * n * np.power((np.power(np.power(10, halo_mass - m), -b)
                                                        + np.power(np.power(10, halo_mass - m), g)), -1)))
    # Add scatter, if requested.
    if not isinstance(type(scatter), type(True)):
        internal_stellar_mass += np.random.normal(scale=scatter, size=np.shape(internal_stellar_mass))

    # Generate the figures, if requested.
    if visual_debugging:
        width = 0.1
        bins = np.arange(9, 15, width)

        hist = np.histogram(internal_stellar_mass, bins=bins)[0]
        hmf = (hist / debugging_volume) / width
        log_smf = np.log10(hmf[hmf != 0])
        adj_bins = bins[0:-1][hmf != 0]

        plt.figure()
        plt.loglog()
        plt.plot(10 ** adj_bins, (10 ** log_smf), label="Grylls 2019")
        plt.xlabel("Stellar Mass")
        plt.ylabel("phi")
        plt.title("Stellar Mass Function, assigned from Pip's code")
        plt.legend()
        save_path = path + 'SMF_Validation.png'
        print("Writing file: {}".format(save_path))
        plt.savefig(save_path)
        plt.close()

    return internal_stellar_mass


if __name__ == "__main__":
    cosmo = 'planck18'
    cosmology = cosmology.setCosmology(cosmo)
    volume = 200**3

    halos = generate_semi_analytic_halo_catalogue(volume, (12, 16, 0.1), 0, 0.7, visual_debugging=True,
                                                  path="./visualValidation/SemiAnalyticCatalog/")
    stellar_mass = halo_mass_to_stellar_mass(halos, 0, visual_debugging=True, debugging_volume=volume,
                                             path="./visualValidation/StellarMass/")
